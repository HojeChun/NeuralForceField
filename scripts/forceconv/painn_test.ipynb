{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# change to your NFF path\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "\n",
    "from nff.data import Dataset, split_train_validation_test, collate_dicts, to_tensor\n",
    "from nff.train import Trainer, get_trainer, get_model, load_model, loss, hooks, metrics, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 0\n",
    "OUTDIR = './sandbox_painn'\n",
    "# batch size used in the original paper\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "if os.path.exists(OUTDIR):\n",
    "    newpath = os.path.join(os.path.dirname(OUTDIR), 'backup')\n",
    "    if os.path.exists(newpath):\n",
    "        shutil.rmtree(newpath)\n",
    "        \n",
    "    shutil.move(OUTDIR, newpath)\n",
    "    \n",
    "dataset = Dataset.from_file('../../tutorials/data/dataset.pth.tar')\n",
    "train, val, test = split_train_validation_test(dataset, val_size=0.2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams = {\"feat_dim\": 128,\n",
    "              \"activation\": \"swish\",\n",
    "              \"n_rbf\": 20,\n",
    "              \"cutoff\": 5.0,\n",
    "              \"num_conv\": 3,\n",
    "              \"output_keys\": [\"energy\"],\n",
    "              \"grad_keys\": [\"energy_grad\"],\n",
    "               # whether to sum outputs from all blocks in the model\n",
    "               # or just the final output block. False in the original\n",
    "               # implementation\n",
    "              \"skip_connection\": False,\n",
    "               # Whether the k parameters in the Bessel basis functions\n",
    "               # are learnable. False originally\n",
    "              \"learnable_k\": False,\n",
    "               # dropout rate in the convolution layers, originally 0\n",
    "               \"conv_dropout\": 0.0,\n",
    "               # dropout rate in the readout layers, originally 0\n",
    "               \"readout_dropout\": 0.0,\n",
    "               # dictionary of means to add to each output key\n",
    "               # (this is optional - if you don't supply it then\n",
    "               # nothing will be added)\n",
    "               \"means\": {\"energy\": train.props['energy'].mean().item()},\n",
    "               # dictionary of standard devations with which to \n",
    "               # multiply each output key\n",
    "               # (this is optional - if you don't supply it then\n",
    "               # nothing will be multiplied)\n",
    "               \"stddevs\": {\"energy\": train.props['energy'].std().item()}\n",
    "              }\n",
    "model = get_model(modelparams, model_type=\"Painn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, collate_fn=collate_dicts,\n",
    "                         sampler=RandomSampler(train))\n",
    "\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "\n",
    "# loss trade-off used in the original paper\n",
    "loss_fn = loss.build_mse_loss(loss_coef={'energy_grad': 0.95, 'energy': 0.05})\n",
    "\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "# learning rate used in the original paper\n",
    "optimizer = Adam(trainable_params, lr=1e-3)\n",
    "\n",
    "\n",
    "train_metrics = [\n",
    "    metrics.MeanAbsoluteError('energy'),\n",
    "    metrics.MeanAbsoluteError('energy_grad')\n",
    "]\n",
    "\n",
    "\n",
    "train_hooks = [\n",
    "    hooks.MaxEpochHook(100),\n",
    "    hooks.CSVHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "    ),\n",
    "    hooks.PrintingHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "        separator = ' | ',\n",
    "        time_strf='%M:%S'\n",
    "    ),\n",
    "    hooks.ReduceLROnPlateauHook(\n",
    "        optimizer=optimizer,\n",
    "        # patience in the original paper\n",
    "        patience=50,\n",
    "        factor=0.5,\n",
    "        min_lr=1e-7,\n",
    "        window_length=1,\n",
    "        stop_after_min=True\n",
    "    )\n",
    "]\n",
    "\n",
    "T = Trainer(\n",
    "    model_path=OUTDIR,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    checkpoint_interval=1,\n",
    "    hooks=train_hooks,\n",
    "    mini_batches=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:03<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:56 |     1 |     1.000e-03 |   122.7045 |         30.1711 |     2.2017 |          3.9614 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 22.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:59 |     2 |     1.000e-03 |    24.3619 |         20.3789 |     0.8893 |          3.2458 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:02 |     3 |     1.000e-03 |    15.6996 |         14.8524 |     0.8315 |          2.8514 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:05 |     4 |     1.000e-03 |    13.6374 |         10.7035 |     1.1208 |          2.3913 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:08 |     5 |     1.000e-03 |     9.5705 |          9.0135 |     0.7422 |          2.1778 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:11 |     6 |     1.000e-03 |     8.1453 |          8.0478 |     0.7405 |          2.0845 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:14 |     7 |     1.000e-03 |     7.5161 |          8.8367 |     0.7511 |          2.2076 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:17 |     8 |     1.000e-03 |     9.0032 |          7.4114 |     0.9319 |          2.0122 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:19 |     9 |     1.000e-03 |     7.1556 |          8.2221 |     0.8903 |          2.1627 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:22 |    10 |     1.000e-03 |     4.7196 |          4.6398 |     0.8042 |          1.5955 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:25 |    11 |     1.000e-03 |     4.6622 |          5.9912 |     0.7777 |          1.7830 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:28 |    12 |     1.000e-03 |     4.0531 |          4.6910 |     0.6164 |          1.5809 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:31 |    13 |     1.000e-03 |     4.5734 |          6.0925 |     0.6802 |          1.8370 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:34 |    14 |     1.000e-03 |     4.1128 |          4.5307 |     0.7015 |          1.5537 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:37 |    15 |     1.000e-03 |     2.8937 |          4.3435 |     0.7337 |          1.4966 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:40 |    16 |     1.000e-03 |     3.1067 |          3.6913 |     0.6404 |          1.3893 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:43 |    17 |     1.000e-03 |     3.1948 |          3.5820 |     0.6003 |          1.3855 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:45 |    18 |     1.000e-03 |     3.3113 |          4.7637 |     0.5421 |          1.6370 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:48 |    19 |     1.000e-03 |     3.1742 |          3.9666 |     0.5328 |          1.4411 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 59/60 [00:02<00:00, 23.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51 |    20 |     1.000e-03 |     3.0573 |          3.5295 |     0.7059 |          1.3522 |              53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 18/60 [00:00<00:01, 24.22it/s]"
     ]
    }
   ],
   "source": [
    "T.train(device=DEVICE, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nff]",
   "language": "python",
   "name": "conda-env-nff-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
