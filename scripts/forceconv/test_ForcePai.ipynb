{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "returning-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# change to your NFF path\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../..\")\n",
    "sys.path.insert(0, \"../../../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from nff.data import Dataset, split_train_validation_test, collate_dicts, to_tensor\n",
    "from nff.train import Trainer, get_trainer, get_model, load_model, loss, hooks, metrics, evaluate\n",
    "\n",
    "import argparse\n",
    "from sigopt import Connection\n",
    "\n",
    "from train import train\n",
    "from forceconv import *\n",
    "\n",
    "from MD17data import *\n",
    "\n",
    "from forcepai import ForcePai\n",
    "# from nff.nn.models import Painn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "south-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-logdir\", type=str, default='./output')\n",
    "parser.add_argument(\"-device\", type=int, default=0)\n",
    "parser.add_argument(\"-data\", type=str, default='ethanol_dft')\n",
    "params = vars(parser.parse_args([]))\n",
    "\n",
    "DEVICE = params['device']\n",
    "OUTDIR = '{}/{}/sandbox'.format(params['logdir'], 'test_ForcePai')\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "lr = 1e-5\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_MD17data(params['data'])\n",
    "dataset = pack_MD17data(data, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorrect-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_train_validation_test(dataset, val_size=0.05, test_size=0.85)\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, collate_fn=collate_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "better-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams = {\"feat_dim\": 128,\n",
    "              \"activation\": \"swish\",\n",
    "              \"n_rbf\": 20,\n",
    "              \"cutoff\": 5.0,\n",
    "              \"num_conv\": 3,\n",
    "              \"output_keys\": [\"energy\"],\n",
    "              \"grad_keys\": [\"energy_grad\"],\n",
    "               # whether to sum outputs from all blocks in the model\n",
    "               # or just the final output block. False in the original\n",
    "               # implementation\n",
    "              \"skip_connection\": False,\n",
    "               # Whether the k parameters in the Bessel basis functions\n",
    "               # are learnable. False originally\n",
    "              \"learnable_k\": False,\n",
    "               # dropout rate in the convolution layers, originally 0\n",
    "               \"conv_dropout\": 0.0,\n",
    "               # dropout rate in the readout layers, originally 0\n",
    "               \"readout_dropout\": 0.0,\n",
    "               # dictionary of means to add to each output key\n",
    "               # (this is optional - if you don't supply it then\n",
    "               # nothing will be added)\n",
    "               # \"means\": {\"energy\": train.props['energy'].mean().item()},\n",
    "               # dictionary of standard devations with which to \n",
    "               # multiply each output key\n",
    "               # (this is optional - if you don't supply it then\n",
    "               # nothing will be multiplied)\n",
    "               # \"stddevs\": {\"energy\": train.props['energy'].std().item()}\n",
    "              }\n",
    "model = ForcePai(modelparams)\n",
    "# model = get_model(modelparams, model_type=\"Painn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "social-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = loss.build_mse_loss(loss_coef={'energy_grad': 1})\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = Adam(trainable_params, lr=lr)\n",
    "train_metrics = [\n",
    "        metrics.MeanAbsoluteError('energy_grad')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "important-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hooks = [\n",
    "    hooks.MaxEpochHook(n_epochs),\n",
    "    hooks.CSVHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "    ),\n",
    "    hooks.PrintingHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "        separator = ' | ',\n",
    "        time_strf='%M:%S'\n",
    "    ),\n",
    "    hooks.ReduceLROnPlateauHook(\n",
    "        optimizer=optimizer,\n",
    "        patience=20,\n",
    "        factor=0.5,\n",
    "        min_lr=1e-7,\n",
    "        window_length=1,\n",
    "        stop_after_min=True\n",
    "    )\n",
    "]\n",
    "\n",
    "T = Trainer(\n",
    "    model_path=OUTDIR,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    checkpoint_interval=1,\n",
    "    hooks=train_hooks,\n",
    "    mini_batches=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pointed-somalia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy_grad | GPU Memory (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:04<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:30 |    11 |     1.000e-03 |    15.6437 |         10.8998 |          2.4804 |              33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:03<00:00, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:34 |    12 |     1.000e-03 |    10.1316 |          7.2117 |          2.0255 |              33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:03<00:00, 26.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:38 |    13 |     1.000e-03 |     8.0491 |          6.3525 |          1.9071 |              33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:02<00:01, 26.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e5df92b0fe85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NeuralForceField/nff/train/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, device, n_epochs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                         self.optim_step(batch_num=eff_batches,\n\u001b[0;32m--> 394\u001b[0;31m                                         device=device)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NeuralForceField/nff/train/trainer.py\u001b[0m in \u001b[0;36moptim_step\u001b[0;34m(self, batch_num, device)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_is_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nff/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nff/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nff/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nff/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T.train(device=DEVICE, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "surgical-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nff.utils.cuda import batch_to, batch_detach\n",
    "data = None\n",
    "for batch in train_loader:\n",
    "    data = batch_to(batch, DEVICE)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "incomplete-discretion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7071, -0.7071,  0.0000],\n",
       "        [ 0.7071,  0.7071,  0.0000],\n",
       "        [ 0.0000,  0.0000,  1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotate = torch.Tensor([[2**.5/2, -2**.5/2, 0],\n",
    "                       [2**.5/2, 2**.5/2, 0],\n",
    "                       [0, 0, 1]]).to(DEVICE)\n",
    "rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "distributed-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nxyz'][:, 1:4] @= rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "associate-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = batch_to(batch_detach(model(data)), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "alpha-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = batch_to(batch_detach(model(data)), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "automated-yacht",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.0715e-08, device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_results['energy_grad'] - (results['energy_grad'] @ rotate)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "entire-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(2, 0)),\n",
       "       values=tensor([], size=(0,)),\n",
       "       device='cuda:0', size=(360, 3), nnz=0, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"offsets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "tutorial-assumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0905e+01,  8.2145e+01, -5.9722e+01],\n",
       "        [-1.0316e+02, -7.6270e+01, -3.6269e+01],\n",
       "        [ 4.3973e+00,  3.2331e+01,  1.1046e+00],\n",
       "        [ 1.8292e+00, -1.9102e+01,  5.2263e+01],\n",
       "        [ 2.2242e+00, -3.6930e+01,  1.8547e+00],\n",
       "        [ 3.4263e+01, -1.2126e+01, -9.8536e+00],\n",
       "        [ 7.2883e+00,  1.7753e+01,  1.7333e+01],\n",
       "        [-3.4666e+00,  3.5572e+01,  2.3576e+01],\n",
       "        [-4.2809e+00, -2.3373e+01,  9.7131e+00],\n",
       "        [-1.8791e+01, -2.1784e+01,  6.1356e+00],\n",
       "        [ 3.9048e+01, -4.0592e+00, -8.6488e+00],\n",
       "        [-2.2611e+01, -1.2323e+01, -1.3219e+01],\n",
       "        [ 1.1123e+01, -5.8336e+00, -5.0618e+00],\n",
       "        [ 1.9847e+01,  9.6305e+00, -1.6908e+01],\n",
       "        [ 7.3554e+00, -3.6178e+00, -6.2092e-03],\n",
       "        [-2.1006e+01,  1.0869e+00, -3.1800e+00],\n",
       "        [-1.7629e+01,  3.1367e+01,  2.4362e+01],\n",
       "        [ 2.6630e+00,  5.5336e+00,  1.6526e+01],\n",
       "        [ 2.7739e+01, -1.7026e+01, -5.5337e+01],\n",
       "        [ 1.2627e+01, -3.8149e+01, -3.0607e+01],\n",
       "        [ 4.9671e+00, -6.2109e+00, -1.0307e+01],\n",
       "        [ 2.5746e+00,  1.5193e+01, -2.7694e+00],\n",
       "        [-1.6905e+01, -1.5999e+01,  2.8970e+01],\n",
       "        [-2.2455e+01,  3.0625e+01,  4.3149e+01],\n",
       "        [ 5.1191e+00,  2.2414e+00,  7.5965e-01],\n",
       "        [ 1.5244e+01, -1.4820e+00,  4.5654e-01],\n",
       "        [-2.8910e+01,  3.0808e+01,  2.5686e+01],\n",
       "        [ 5.6563e+01, -1.1923e+01,  1.0420e+01],\n",
       "        [ 2.8204e+01, -5.1452e+01,  1.2001e+01],\n",
       "        [-1.9551e+01,  3.0533e+01, -5.3519e+00],\n",
       "        [-7.9088e+00, -8.5181e+00, -4.5333e+00],\n",
       "        [ 1.8246e+00, -2.4253e+01,  3.2079e+00],\n",
       "        [-2.8423e+00,  5.1299e+00, -9.2652e+00],\n",
       "        [-4.9254e+01,  2.5504e+01,  2.1449e+01],\n",
       "        [ 7.2779e+00,  1.2052e+01, -2.5571e+01],\n",
       "        [-1.4313e+01,  2.2927e+01, -2.3562e+00],\n",
       "        [-2.1091e+01,  1.5505e+01,  4.1070e+01],\n",
       "        [ 1.8962e+01, -3.3028e+01, -6.3067e+01],\n",
       "        [ 1.8586e+01, -1.7815e+01, -6.1843e+01],\n",
       "        [ 2.9981e+01, -1.5727e+01,  5.7149e+00],\n",
       "        [ 4.4888e+00, -2.7433e+00, -4.5405e+00],\n",
       "        [-6.9452e+00, -1.6159e+01,  3.1227e+01],\n",
       "        [ 1.8159e+00,  1.8884e+01,  1.5005e+01],\n",
       "        [-4.1058e+01,  2.2291e+01,  1.0189e+01],\n",
       "        [-4.7390e+00,  2.8793e+01,  2.6243e+01],\n",
       "        [-1.1130e+01, -4.1419e+01, -2.6397e+01],\n",
       "        [ 4.6301e+01, -5.0565e+00,  3.5900e+01],\n",
       "        [-6.6011e-01, -2.7497e+00, -3.6863e+00],\n",
       "        [ 2.2066e+01,  2.7636e+01, -2.4436e+01],\n",
       "        [-3.5055e-01, -1.4913e+01,  1.2662e+01],\n",
       "        [-1.1070e+01,  1.3326e+01,  9.7373e+00],\n",
       "        [-1.5402e+01,  1.8341e+01, -7.9167e+00],\n",
       "        [-9.6585e+00,  4.9983e-01, -1.9897e+00],\n",
       "        [-2.0096e+01,  4.3359e+00,  6.1268e+00],\n",
       "        [ 5.5804e+01,  4.1505e+01, -1.5482e+01],\n",
       "        [-1.5645e+01, -2.5525e+01,  4.6057e+01],\n",
       "        [-4.4817e+01, -4.5578e+01,  4.0263e+01],\n",
       "        [-2.0679e+01, -2.0599e+01, -2.1652e+01],\n",
       "        [-1.5429e+01, -2.3745e+01,  8.4537e+00],\n",
       "        [ 1.1414e+01,  1.0215e+01,  1.1538e+01],\n",
       "        [ 1.1642e-01,  3.1382e+01, -2.4899e+01],\n",
       "        [ 1.6130e+01, -7.2097e+00, -2.1407e+01],\n",
       "        [ 1.3105e+01,  3.9554e+01, -2.2872e+01],\n",
       "        [ 3.0131e+01, -3.2195e+01, -5.6924e+01],\n",
       "        [ 1.0736e+00, -1.9088e+01,  4.8770e+01],\n",
       "        [-8.0193e+00,  1.1848e+01, -2.8654e+01],\n",
       "        [-1.8077e+01, -3.0555e+00,  1.9236e+01],\n",
       "        [-3.6543e+00,  3.3316e+01,  2.6206e+01],\n",
       "        [ 7.6059e-01,  1.4819e+00, -7.3405e+00],\n",
       "        [ 6.4088e+00, -1.9973e+01, -1.3139e+01],\n",
       "        [-3.4130e+00,  4.0912e+01, -3.6632e-01],\n",
       "        [-5.2108e+00, -1.3246e+01,  1.2212e+01],\n",
       "        [ 3.3755e+00,  3.4298e-02, -5.8202e+00],\n",
       "        [-7.4981e+01,  4.6329e+01,  1.3509e+01],\n",
       "        [ 1.6045e+01, -4.0811e+01,  4.0126e+01],\n",
       "        [ 2.5404e+01, -3.0489e+01,  3.1601e+00],\n",
       "        [-4.6739e+00,  1.4438e+01,  6.1110e+00],\n",
       "        [ 1.9684e+01, -4.0071e+01, -4.9457e+01],\n",
       "        [ 3.0188e+01,  4.3457e+00,  4.7888e+00],\n",
       "        [-6.1751e-01,  1.1129e+01,  2.1658e+01],\n",
       "        [-1.4423e+01,  3.5093e+01, -3.4077e+01],\n",
       "        [ 3.8521e+00, -2.8131e+00,  2.4030e-01],\n",
       "        [-1.7809e+01,  5.6263e+00, -5.2276e+00],\n",
       "        [ 2.2682e+00,  9.0598e+00,  9.8183e+00],\n",
       "        [ 6.0321e+00, -1.2112e+01, -1.1041e+01],\n",
       "        [-8.0762e-01, -9.3043e+00, -2.3162e+00],\n",
       "        [ 2.3308e+01, -1.0839e+01,  3.5584e+00],\n",
       "        [-3.2651e+00,  1.6402e+00,  1.3098e+01],\n",
       "        [ 3.9554e+00,  1.5672e+01, -3.1270e+00],\n",
       "        [-1.7534e+01,  3.0701e+00, -5.0036e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['energy_grad'] @ rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "weekly-validation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['energy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-logging",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nff]",
   "language": "python",
   "name": "nff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
