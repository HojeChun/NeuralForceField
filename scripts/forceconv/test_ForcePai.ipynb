{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "returning-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# change to your NFF path\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../..\")\n",
    "sys.path.insert(0, \"../../../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from nff.data import Dataset, split_train_validation_test, collate_dicts, to_tensor\n",
    "from nff.train import Trainer, get_trainer, get_model, load_model, loss, hooks, metrics, evaluate\n",
    "\n",
    "import argparse\n",
    "from sigopt import Connection\n",
    "\n",
    "from train import train\n",
    "from forceconv import *\n",
    "\n",
    "from MD17data import *\n",
    "\n",
    "from forcepai import ForcePai\n",
    "# from nff.nn.models import Painn\n",
    "from forcedime import ForceDime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "south-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-logdir\", type=str, default='./output')\n",
    "parser.add_argument(\"-device\", type=int, default=0)\n",
    "parser.add_argument(\"-data\", type=str, default='ethanol_dft')\n",
    "params = vars(parser.parse_args([]))\n",
    "\n",
    "DEVICE = params['device']\n",
    "OUTDIR = '{}/{}/sandbox'.format(params['logdir'], 'test_ForcePai')\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "lr = 1e-5\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:29<00:00, 341.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding kj and ji indices with 1 parallel processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2796.44it/s]\n"
     ]
    }
   ],
   "source": [
    "data = get_MD17data(params['data'])\n",
    "dataset = pack_MD17data(data, 10000)\n",
    "dataset.generate_angle_list()\n",
    "dataset.generate_kj_ji()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorrect-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_train_validation_test(dataset, val_size=0.05, test_size=0.85)\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, collate_fn=collate_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "better-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelparams = {\"feat_dim\": 128,\n",
    "#               \"activation\": \"swish\",\n",
    "#               \"n_rbf\": 20,\n",
    "#               \"cutoff\": 5.0,\n",
    "#               \"num_conv\": 3,\n",
    "#               \"output_keys\": [\"energy\"],\n",
    "#               \"grad_keys\": [\"energy_grad\"],\n",
    "#                # whether to sum outputs from all blocks in the model\n",
    "#                # or just the final output block. False in the original\n",
    "#                # implementation\n",
    "#               \"skip_connection\": False,\n",
    "#                # Whether the k parameters in the Bessel basis functions\n",
    "#                # are learnable. False originally\n",
    "#               \"learnable_k\": False,\n",
    "#                # dropout rate in the convolution layers, originally 0\n",
    "#                \"conv_dropout\": 0.0,\n",
    "#                # dropout rate in the readout layers, originally 0\n",
    "#                \"readout_dropout\": 0.0,\n",
    "#                # dictionary of means to add to each output key\n",
    "#                # (this is optional - if you don't supply it then\n",
    "#                # nothing will be added)\n",
    "#                # \"means\": {\"energy\": train.props['energy'].mean().item()},\n",
    "#                # dictionary of standard devations with which to \n",
    "#                # multiply each output key\n",
    "#                # (this is optional - if you don't supply it then\n",
    "#                # nothing will be multiplied)\n",
    "#                # \"stddevs\": {\"energy\": train.props['energy'].std().item()}\n",
    "#               }\n",
    "# model = ForcePai(modelparams).to(DEVICE)\n",
    "model = ForceDime(n_rbf=16, cutoff=5, \n",
    "                envelope_p=8, l_spher=6, \n",
    "                n_spher=6, embed_dim=128, \n",
    "                activation='ReLU', \n",
    "                n_bilinear=8, \n",
    "                n_convolutions=6).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "social-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = loss.build_mse_loss(loss_coef={'energy_grad': 1})\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = Adam(trainable_params, lr=lr)\n",
    "train_metrics = [\n",
    "        metrics.MeanAbsoluteError('energy_grad')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hooks = [\n",
    "    hooks.MaxEpochHook(n_epochs),\n",
    "    hooks.CSVHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "    ),\n",
    "    hooks.PrintingHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "        separator = ' | ',\n",
    "        time_strf='%M:%S'\n",
    "    ),\n",
    "    hooks.ReduceLROnPlateauHook(\n",
    "        optimizer=optimizer,\n",
    "        patience=20,\n",
    "        factor=0.5,\n",
    "        min_lr=1e-7,\n",
    "        window_length=1,\n",
    "        stop_after_min=True\n",
    "    )\n",
    "]\n",
    "\n",
    "T = Trainer(\n",
    "    model_path=OUTDIR,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    checkpoint_interval=1,\n",
    "    hooks=train_hooks,\n",
    "    mini_batches=1\n",
    ")\n",
    "\n",
    "T.train(device=DEVICE, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "surgical-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nff.utils.cuda import batch_to, batch_detach\n",
    "data = None\n",
    "for batch in train_loader:\n",
    "    data = batch_to(batch, DEVICE)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incomplete-discretion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7071, -0.7071,  0.0000],\n",
       "        [ 0.7071,  0.7071,  0.0000],\n",
       "        [ 0.0000,  0.0000,  1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotate = torch.Tensor([[2**.5/2, -2**.5/2, 0],\n",
    "                       [2**.5/2, 2**.5/2, 0],\n",
    "                       [0, 0, 1]]).to(DEVICE)\n",
    "rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "distributed-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nxyz'][:, 1:4] @= rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "associate-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "laden-assignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4232,  0.0064, -1.0280],\n",
       "        [-1.4240, -0.0094, -1.0365],\n",
       "        [-1.4538, -0.0085, -1.0000],\n",
       "        ...,\n",
       "        [-1.4221,  0.0074, -1.0057],\n",
       "        [-1.4289, -0.0064, -1.0123],\n",
       "        [-1.4298,  0.0140, -1.0010]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2] @ rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "alpha-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "entire-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0109, -1.0019, -1.0280],\n",
       "        [-1.0087, -1.0050, -1.0365],\n",
       "        [-1.0577, -1.0006, -1.0000],\n",
       "        ...,\n",
       "        [-1.0036, -1.0074, -1.0057],\n",
       "        [-1.0200, -1.0010, -1.0123],\n",
       "        [-1.0157, -1.0061, -1.0010]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "applied-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nff.utils.tools import make_directed\n",
    "nbrs, _ = make_directed(batch['nbr_list'])\n",
    "nxyz = data['nxyz']\n",
    "xyz = nxyz[:, 1:]\n",
    "xyz.requires_grad = True\n",
    "\n",
    "def norm(vec):\n",
    "    EPS = 1e-15\n",
    "    result = ((vec ** 2 + EPS).sum(-1)) ** 0.5\n",
    "    return result\n",
    "\n",
    "def func(xyz):\n",
    "    r_ij = xyz[nbrs[:, 1]] - xyz[nbrs[:, 0]]\n",
    "    dist = norm(r_ij)\n",
    "    unit = r_ij / dist.reshape(-1, 1)\n",
    "    return unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "regional-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.autograd.functional.jacobian(func, xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "guided-respondent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 3, 90, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "rocky-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6741,  0.0282,  0.0122],\n",
       "          [ 0.6741, -0.0282, -0.0122],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0282, -0.1079,  0.2459],\n",
       "          [-0.0282,  0.1079, -0.2459],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0122,  0.2459, -0.5690],\n",
       "          [-0.0122, -0.2459,  0.5690],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.6496, -0.1210,  0.1654],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.6496,  0.1210, -0.1654],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.1210, -0.4879, -0.3095],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.1210,  0.4879,  0.3095],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.1654, -0.3095, -0.2910],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.1654,  0.3095,  0.2910],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0812,  0.1748,  0.2022],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.1748, -0.9267,  0.0402],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.2022,  0.0402, -0.9150],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.5248,  0.0055, -0.0900],\n",
       "          [-0.5248, -0.0055,  0.0900],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0055,  0.5383,  0.0321],\n",
       "          [-0.0055, -0.5383, -0.0321],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [-0.0900,  0.0321,  0.0175],\n",
       "          [ 0.0900, -0.0321, -0.0175],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.2133,  0.0499,  0.1365],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.2133, -0.0499, -0.1365]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0499,  0.2871, -0.0688],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.0499, -0.2871,  0.0688]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.1365, -0.0688,  0.1242],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.1365,  0.0688, -0.1242]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.1018,  0.1484,  0.0965],\n",
       "          [-0.1018, -0.1484, -0.0965]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.1484,  0.3379, -0.0466],\n",
       "          [-0.1484, -0.3379,  0.0466]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0965, -0.0466,  0.3792],\n",
       "          [-0.0965,  0.0466, -0.3792]]]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "induced-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ij = xyz[nbrs[:, 1]] - xyz[nbrs[:, 0]]\n",
    "dis_vec = r_ij\n",
    "dis = norm(r_ij).unsqueeze(-1)\n",
    "dis_adjoint = dis_vec / dis  # N_e * 3\n",
    "dis_order2 = dis.unsqueeze(-1)\n",
    "eye3 = torch.eye(3).unsqueeze(0).to(dis)\n",
    "b = ((-dis_order2*eye3) - (r_ij.unsqueeze(-2)*r_ij.unsqueeze(-1))/dis_order2) / dis_order2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "female-fitness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 3, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "enormous-merit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "material-exercise",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 90, 1]' is invalid for input of size 720",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-0e032e8cdda1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NeuralForceField/nff/utils/scatter.py\u001b[0m in \u001b[0;36mscatter_add\u001b[0;34m(src, index, dim, out, dim_size, fill_value)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NeuralForceField/nff/utils/scatter.py\u001b[0m in \u001b[0;36mgen\u001b[0;34m(src, index, dim, out, dim_size, fill_value)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mindex_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mindex_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Generate output tensor if not given.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1, 90, 1]' is invalid for input of size 720"
     ]
    }
   ],
   "source": [
    "from nff.utils.scatter import scatter_add\n",
    "scatter_add(a, nbrs[:,0], dim=2, dim_size=90) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-american",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nff]",
   "language": "python",
   "name": "nff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
